"use strict";(self.webpackChunkcasbin_website_v2=self.webpackChunkcasbin_website_v2||[]).push([[3349],{3905:(e,t,l)=>{l.d(t,{Zo:()=>u,kt:()=>m});var a=l(7294);function r(e,t,l){return t in e?Object.defineProperty(e,t,{value:l,enumerable:!0,configurable:!0,writable:!0}):e[t]=l,e}function n(e,t){var l=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),l.push.apply(l,a)}return l}function i(e){for(var t=1;t<arguments.length;t++){var l=null!=arguments[t]?arguments[t]:{};t%2?n(Object(l),!0).forEach((function(t){r(e,t,l[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(l)):n(Object(l)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(l,t))}))}return e}function o(e,t){if(null==e)return{};var l,a,r=function(e,t){if(null==e)return{};var l,a,r={},n=Object.keys(e);for(a=0;a<n.length;a++)l=n[a],t.indexOf(l)>=0||(r[l]=e[l]);return r}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(a=0;a<n.length;a++)l=n[a],t.indexOf(l)>=0||Object.prototype.propertyIsEnumerable.call(e,l)&&(r[l]=e[l])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),l=t;return e&&(l="function"==typeof e?e(t):i(i({},t),e)),l},u=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var l=e.components,r=e.mdxType,n=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),p=c(l),m=r,v=p["".concat(s,".").concat(m)]||p[m]||d[m]||n;return l?a.createElement(v,i(i({ref:t},u),{},{components:l})):a.createElement(v,i({ref:t},u))}));function m(e,t){var l=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var n=l.length,i=new Array(n);i[0]=p;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var c=2;c<n;c++)i[c]=l[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,l)}p.displayName="MDXCreateElement"},8292:(e,t,l)=>{l.r(t),l.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>n,metadata:()=>o,toc:()=>c});var a=l(7462),r=(l(7294),l(3905));const n={id:"blp",title:"BLP",description:"Bell-LaPadula model in Casbin",keywords:["blp","bell-lapadula","security model"],authors:["nodece"]},i=void 0,o={unversionedId:"blp",id:"blp",title:"BLP",description:"Bell-LaPadula model in Casbin",source:"@site/i18n/ar/docusaurus-plugin-content-docs/current/BLP.mdx",sourceDirName:".",slug:"/blp",permalink:"/ar/docs/blp",draft:!1,editUrl:"https://github.com/casbin/casbin-website-v2/edit/master/docs/BLP.mdx",tags:[],version:"current",frontMatter:{id:"blp",title:"BLP",description:"Bell-LaPadula model in Casbin",keywords:["blp","bell-lapadula","security model"],authors:["nodece"]},sidebar:"docs",previous:{title:"ABAC",permalink:"/ar/docs/abac"},next:{title:"Biba",permalink:"/ar/docs/biba"}},s={},c=[{value:"Overview",id:"overview",level:2},{value:"Model",id:"model",level:2},{value:"Policy",id:"policy",level:2},{value:"Examples",id:"examples",level:2},{value:"Request Examples",id:"request-examples",level:3},{value:"Security Levels",id:"security-levels",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Implementation Notes",id:"implementation-notes",level:2}],u={toc:c};function d(e){let{components:t,...l}=e;return(0,r.kt)("wrapper",(0,a.Z)({},u,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"overview"},"Overview"),(0,r.kt)("p",null,"The Bell-LaPadula (BLP) model is a formal state transition model of computer security policy that describes a set of access control rules which use security labels on objects and clearances for subjects. It was developed by David Elliott Bell and Leonard J. LaPadula in 1973."),(0,r.kt)("h2",{id:"model"},"Model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-conf"},'[request_definition]\nr = sub, sub_level, obj, obj_level, act\n\n[policy_definition]\np = sub, obj, act\n\n[role_definition]\ng = _, _\n\n[policy_effect]\ne = some(where (p.eft == allow))\n\n[matchers]\nm = (r.act == "read" && r.sub_level >= r.obj_level) || (r.act == "write" && r.sub_level <= r.obj_level)\n')),(0,r.kt)("h2",{id:"policy"},"Policy"),(0,r.kt)("p",null,"BLP model typically doesn't require explicit policy rules as the access control is determined by the security levels of subjects and objects. The matcher function implements the BLP rules:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"No Read Up"),": A subject cannot read an object with a higher security level"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"No Write Down"),": A subject cannot write to an object with a lower security level")),(0,r.kt)("h2",{id:"examples"},"Examples"),(0,r.kt)("h3",{id:"request-examples"},"Request Examples"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},"alice, 3, data1, 1, read    # alice (level 3) reads data1 (level 1) - ALLOWED\nbob, 2, data2, 2, read      # bob (level 2) reads data2 (level 2) - ALLOWED\ncharlie, 1, data1, 1, read  # charlie (level 1) reads data1 (level 1) - ALLOWED\nbob, 2, data3, 3, read      # bob (level 2) reads data3 (level 3) - DENIED (No Read Up)\ncharlie, 1, data2, 2, read  # charlie (level 1) reads data2 (level 2) - DENIED (No Read Up)\n\nalice, 3, data3, 3, write   # alice (level 3) writes data3 (level 3) - ALLOWED\nbob, 2, data3, 3, write     # bob (level 2) writes data3 (level 3) - ALLOWED\ncharlie, 1, data2, 2, write # charlie (level 1) writes data2 (level 2) - ALLOWED\nalice, 3, data1, 1, write   # alice (level 3) writes data1 (level 1) - DENIED (No Write Down)\nbob, 2, data1, 1, write     # bob (level 2) writes data1 (level 1) - DENIED (No Write Down)\n")),(0,r.kt)("h2",{id:"security-levels"},"Security Levels"),(0,r.kt)("p",null,"In the BLP model, security levels are typically represented as integers where higher numbers indicate higher security levels:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Level 1: Public/Unclassified"),(0,r.kt)("li",{parentName:"ul"},"Level 2: Confidential"),(0,r.kt)("li",{parentName:"ul"},"Level 3: Secret"),(0,r.kt)("li",{parentName:"ul"},"Level 4: Top Secret")),(0,r.kt)("h2",{id:"use-cases"},"Use Cases"),(0,r.kt)("p",null,"BLP model is commonly used in:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Military and government systems"),(0,r.kt)("li",{parentName:"ul"},"Financial institutions"),(0,r.kt)("li",{parentName:"ul"},"Healthcare systems"),(0,r.kt)("li",{parentName:"ul"},"Any environment requiring strict information flow control")),(0,r.kt)("h2",{id:"implementation-notes"},"Implementation Notes"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The model enforces mandatory access control (MAC)"),(0,r.kt)("li",{parentName:"ul"},"Security levels are assigned by system administrators"),(0,r.kt)("li",{parentName:"ul"},"Access decisions are based purely on security levels, not user identity"),(0,r.kt)("li",{parentName:"ul"},"The model prevents information leakage through read/write operations")))}d.isMDXComponent=!0}}]);